{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration\n",
    "\n",
    "In this notebook I am going to explore the data and processes of the first project of the NanoDegree Data Engineering Program.\n",
    "\n",
    "- 'Walk' the directory with Path\n",
    "- Retrieve all JSON files\n",
    "- Load them into Pandas \n",
    "- Explore and clean\n",
    "- Ready for insert -> NOTE: watch out with insertion in the database, something like auto increment oid should be ON \n",
    "- Create a SQL database (SQLlite for training purposes?)\n",
    "- Insert the transformed and cleaned data\n",
    "- Bonus: Logging (!) -> try to keep it simple but logging is essential for these tasks -> especially for Exception statements etc.\n",
    "\n",
    "Make sure to write clean robust code, add sensible checks -> assert. Eventually this will become your etl.ipynb \n",
    "\n",
    "----------------------------\n",
    "\n",
    "After the first exploration, there appears to be a recurring process:\n",
    "- Collect the data for a particular table\n",
    "- Assert that the data is correct\n",
    "- Insert the data into the specified table\n",
    "- Verify the results\n",
    "\n",
    "There is probably a lot of functionality we can re-use for each table.\n",
    "\n",
    "#### Find JSON files and return the directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_path_list(file_path: str, extension: str = '.json') -> list:\n",
    "    \"\"\"Returns a list of Paths of all the files with the extension. All subdirectories of file_path are included.\n",
    "    \n",
    "    Example\n",
    "        from pathlib import Path\n",
    "        \n",
    "        data_path = Path('.') / 'data'\n",
    "        csv_path_list = create_path_list(data_path, '.csv')     \n",
    "    \"\"\"\n",
    "    return_list = [x for x in file_path.glob(f\"**/*{extension}\")]\n",
    "    print(f\"{file_path} contains {len(return_list)} {extension} files.\")    \n",
    "    \n",
    "    return return_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('.') / 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data contains 101 .json files.\n"
     ]
    }
   ],
   "source": [
    "data_path_list = create_path_list(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process song data\n",
    "\n",
    "From this data 2 tables are created:\n",
    "- songs - songs in music database -> song_id, title, artist_id, year, duration\n",
    "- artists - artists in music database -> artist_id, name, location, latitude, longitude\n",
    "\n",
    "Create a list of tuples for a direct insert into the Postgres table. Validate each row, concatenate to a Dataframe, transform to a list of tuples and return.\n",
    "\n",
    "https://realpython.com/python-exceptions/#the-assertionerror-exception\n",
    "\n",
    "Observations:\n",
    "- Songs: year contains 0 values\n",
    "\n",
    "#### Songs table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\song_data contains 71 .json files.\n"
     ]
    }
   ],
   "source": [
    "song_path_list = create_path_list(data_path / 'song_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_columns = sorted(['title', 'song_id', 'year', 'duration'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_assertions(df: pd.DataFrame, target_columns: list) -> None:\n",
    "    \"\"\"Assert statements to make sure the retrieved data is valid and clean before insertion into the Postgres table.\"\"\"     \n",
    "    df_cols = df.columns.str.lower() \n",
    "    found_cols = [x for x in df_cols if x in target_columns]\n",
    "    \n",
    "    assert sorted(found_cols) == sorted(target_columns), f\"The columns do not match.\"\n",
    "    assert df[target_columns].isnull().values.any() == False, f\"Missing values in not nullable target columns.\"\n",
    "    # assert data types of each column   \n",
    "    # assert any constraint important to the Postgres Table \n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df = pd.DataFrame(columns=song_columns)\n",
    "\n",
    "for idx, file in enumerate(song_path_list):\n",
    "    temp_df = pd.read_json(file, lines=True)    \n",
    "    try:\n",
    "        df_assertions(temp_df, song_columns)\n",
    "    except AssertionError as error:\n",
    "        print(f\"Error @ file {idx} {file}: {error} NOTE: this file will not be inserted.\")\n",
    "    else:\n",
    "        song_df = song_df.append(temp_df[song_columns], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'song_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-1081eb620e01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msong_table_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msong_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'song_df' is not defined"
     ]
    }
   ],
   "source": [
    "song_table_data = list(song_df.to_records(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Artists table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df[['artist_name', 'artist_location', 'artist_latitude', 'artist_longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_columns = ['artist_id', 'artist_name', 'artist_location', 'artist_latitude', 'artist_longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df = pd.DataFrame(columns=artist_columns)\n",
    "\n",
    "for idx, file in enumerate(song_path_list):\n",
    "    temp_df = pd.read_json(file, lines=True)    \n",
    "    artist_df = artist_df.append(temp_df[artist_columns], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df.replace({'': None, np.nan: None})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging data\n",
    "\n",
    "There are 2 tables we want to extract from logging data\n",
    "- users\n",
    "- time\n",
    "\n",
    "Challenge:\n",
    "- users needs to be filtered on ['auth']=='Logged In']\n",
    "- time needs to be filterd on ['page']=='NextSong'\n",
    "- Ideally, we do not want to load the data twice since that would cause A lot of overhead...\n",
    "\n",
    "Create a function which takes temp_df as input, and returns a temp_users and temp_time df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\log_data contains 30 .json files.\n"
     ]
    }
   ],
   "source": [
    "log_path_list = create_path_list(data_path / 'log_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = pd.read_json(log_path_list[0], lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expands_dfs(temp_df):\n",
    "    \"\"\"Returns 2 dataframes which can be used for the users and time tables in Postgres.\"\"\"\n",
    "    users_columns = ['userId', 'firstName', 'lastName', 'gender', 'level']\n",
    "    time_columns = ['ts']\n",
    "    \n",
    "    song_df = temp_df[temp_df['auth']=='Logged In']\n",
    "    time_df = temp_df[temp_df['page']=='NextSong']\n",
    "    \n",
    "    return (song_df[users_columns], time_df[time_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    userId firstName lastName gender level\n",
       " 0       39    Walter     Frye      M  free\n",
       " 1        8    Kaylee  Summers      F  free\n",
       " 2        8    Kaylee  Summers      F  free\n",
       " 3        8    Kaylee  Summers      F  free\n",
       " 4        8    Kaylee  Summers      F  free\n",
       " 5        8    Kaylee  Summers      F  free\n",
       " 6        8    Kaylee  Summers      F  free\n",
       " 7        8    Kaylee  Summers      F  free\n",
       " 8        8    Kaylee  Summers      F  free\n",
       " 9        8    Kaylee  Summers      F  free\n",
       " 10      10    Sylvie     Cruz      F  free\n",
       " 11      26      Ryan    Smith      M  free\n",
       " 12      26      Ryan    Smith      M  free\n",
       " 13      26      Ryan    Smith      M  free\n",
       " 14     101    Jayden      Fox      M  free,\n",
       "                ts\n",
       " 2   1541106106796\n",
       " 4   1541106352796\n",
       " 5   1541106496796\n",
       " 6   1541106673796\n",
       " 7   1541107053796\n",
       " 8   1541107493796\n",
       " 9   1541107734796\n",
       " 10  1541108520796\n",
       " 12  1541109125796\n",
       " 13  1541109325796\n",
       " 14  1541110994796)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expands_dfs(log_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_df = pd.DataFrame()\n",
    "time_df = pd.DataFrame()\n",
    "\n",
    "for idx, file in enumerate(log_path_list):\n",
    "    temp_df = pd.read_json(file, lines=True)   \n",
    "    \n",
    "    temp_song, temp_time = expands_dfs(temp_df)\n",
    "    \n",
    "    song_df = song_df.append(temp_song, ignore_index=True)\n",
    "    time_df = time_df.append(temp_time, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1541106106796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1541106352796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1541106496796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1541106673796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1541107053796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815</th>\n",
       "      <td>1543603205796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6816</th>\n",
       "      <td>1543603476796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6817</th>\n",
       "      <td>1543603678796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6818</th>\n",
       "      <td>1543603884796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6819</th>\n",
       "      <td>1543607664796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6820 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ts\n",
       "0     1541106106796\n",
       "1     1541106352796\n",
       "2     1541106496796\n",
       "3     1541106673796\n",
       "4     1541107053796\n",
       "...             ...\n",
       "6815  1543603205796\n",
       "6816  1543603476796\n",
       "6817  1543603678796\n",
       "6818  1543603884796\n",
       "6819  1543607664796\n",
       "\n",
       "[6820 rows x 1 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-ed4e7fbaf360>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\envs\\regular_notebook\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_extract_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mis_empty_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m                 \u001b[1;31m# gh-17261\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                 warnings.warn(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\regular_notebook\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36mis_empty_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    594\u001b[0m     \u001b[0mis_none\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[0mis_list_like_without_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m     \u001b[0mis_simple_empty\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_list_like_without_dtype\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    597\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mis_none\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_simple_empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\regular_notebook\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1330\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "time_df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-01 21:01:46.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-01 21:05:52.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-01 21:08:16.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-01 21:11:13.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-01 21:17:33.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815</th>\n",
       "      <td>2018-11-30 18:40:05.796</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6816</th>\n",
       "      <td>2018-11-30 18:44:36.796</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6817</th>\n",
       "      <td>2018-11-30 18:47:58.796</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6818</th>\n",
       "      <td>2018-11-30 18:51:24.796</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6819</th>\n",
       "      <td>2018-11-30 19:54:24.796</td>\n",
       "      <td>19</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6813 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  start_time  hour  day  month  year  weekday\n",
       "0    2018-11-01 21:01:46.796    21   44     11  2018        3\n",
       "1    2018-11-01 21:05:52.796    21   44     11  2018        3\n",
       "2    2018-11-01 21:08:16.796    21   44     11  2018        3\n",
       "3    2018-11-01 21:11:13.796    21   44     11  2018        3\n",
       "4    2018-11-01 21:17:33.796    21   44     11  2018        3\n",
       "...                      ...   ...  ...    ...   ...      ...\n",
       "6815 2018-11-30 18:40:05.796    18   48     11  2018        4\n",
       "6816 2018-11-30 18:44:36.796    18   48     11  2018        4\n",
       "6817 2018-11-30 18:47:58.796    18   48     11  2018        4\n",
       "6818 2018-11-30 18:51:24.796    18   48     11  2018        4\n",
       "6819 2018-11-30 19:54:24.796    19   48     11  2018        4\n",
       "\n",
       "[6813 rows x 6 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_ms(time_df['ts']).drop_duplicates(subset='start_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_ms(ms_series: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"Expands a Pandas series with milliseconds with several datetime attributes.\"\"\"\n",
    "    df = pd.DataFrame({'start_time': pd.to_datetime(ms_series, unit='ms')})\n",
    "    \n",
    "    df['hour'] = df['start_time'].dt.hour\n",
    "    df['day'] = df['start_time'].dt.day\n",
    "    df['day'] = df['start_time'].dt.isocalendar().week  \n",
    "    df['month'] = df['start_time'].dt.month\n",
    "    df['year'] = df['start_time'].dt.year\n",
    "    df['weekday'] = df['start_time'].dt.weekday\n",
    "\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in time_df:\n",
    "    pd.DataFrame({'start_time': pd.to_datetime(time, unit='ms')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(time_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\log_data contains 30 .json files.\n"
     ]
    }
   ],
   "source": [
    "log_path_list = create_path_list(data_path / 'log_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = pd.read_json(log_path_list[0], lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Walter</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Frye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>San Francisco-Oakland-Hayward, CA</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>1540919166796</td>\n",
       "      <td>38</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1541105830796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Summers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1541106106796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Des'ree</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>Summers</td>\n",
       "      <td>246.30812</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>You Gotta Be</td>\n",
       "      <td>200</td>\n",
       "      <td>1541106106796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Summers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>GET</td>\n",
       "      <td>Upgrade</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1541106132796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mr Oizo</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>Summers</td>\n",
       "      <td>144.03873</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>Flat 55</td>\n",
       "      <td>200</td>\n",
       "      <td>1541106352796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist       auth firstName gender  itemInSession lastName     length  \\\n",
       "0     None  Logged In    Walter      M              0     Frye        NaN   \n",
       "1     None  Logged In    Kaylee      F              0  Summers        NaN   \n",
       "2  Des'ree  Logged In    Kaylee      F              1  Summers  246.30812   \n",
       "3     None  Logged In    Kaylee      F              2  Summers        NaN   \n",
       "4  Mr Oizo  Logged In    Kaylee      F              3  Summers  144.03873   \n",
       "\n",
       "  level                           location method      page   registration  \\\n",
       "0  free  San Francisco-Oakland-Hayward, CA    GET      Home  1540919166796   \n",
       "1  free        Phoenix-Mesa-Scottsdale, AZ    GET      Home  1540344794796   \n",
       "2  free        Phoenix-Mesa-Scottsdale, AZ    PUT  NextSong  1540344794796   \n",
       "3  free        Phoenix-Mesa-Scottsdale, AZ    GET   Upgrade  1540344794796   \n",
       "4  free        Phoenix-Mesa-Scottsdale, AZ    PUT  NextSong  1540344794796   \n",
       "\n",
       "   sessionId          song  status             ts  \\\n",
       "0         38          None     200  1541105830796   \n",
       "1        139          None     200  1541106106796   \n",
       "2        139  You Gotta Be     200  1541106106796   \n",
       "3        139          None     200  1541106132796   \n",
       "4        139       Flat 55     200  1541106352796   \n",
       "\n",
       "                                           userAgent  userId  \n",
       "0  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...      39  \n",
       "1  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  \n",
       "2  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  \n",
       "3  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  \n",
       "4  \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 18 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   artist         11 non-null     object \n",
      " 1   auth           15 non-null     object \n",
      " 2   firstName      15 non-null     object \n",
      " 3   gender         15 non-null     object \n",
      " 4   itemInSession  15 non-null     int64  \n",
      " 5   lastName       15 non-null     object \n",
      " 6   length         11 non-null     float64\n",
      " 7   level          15 non-null     object \n",
      " 8   location       15 non-null     object \n",
      " 9   method         15 non-null     object \n",
      " 10  page           15 non-null     object \n",
      " 11  registration   15 non-null     int64  \n",
      " 12  sessionId      15 non-null     int64  \n",
      " 13  song           11 non-null     object \n",
      " 14  status         15 non-null     int64  \n",
      " 15  ts             15 non-null     int64  \n",
      " 16  userAgent      15 non-null     object \n",
      " 17  userId         15 non-null     int64  \n",
      "dtypes: float64(1), int64(6), object(11)\n",
      "memory usage: 2.2+ KB\n"
     ]
    }
   ],
   "source": [
    "log_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df['page'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_songs = log_df[log_df['page']=='NextSong']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Users -> [user_id, first_name, last_name, gender, level]\n",
    "Levels feels like something we should update... hence the hints on the cheat sheet :D -> take time into account, the files are in chronological order\n",
    "\n",
    "- Per file we should only keep one row per userid\n",
    "- If the userid already exists, check if we can update gender and / or level, else skip\n",
    "- make sure to read the files in the correct order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_dtype_dict = {'userId': int,\n",
    "                    'firstName': str, \n",
    "                    'lastName': str,\n",
    "                    'gender': str,\n",
    "                    'level': str} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_columns = ['userId', 'firstName', 'lastName', 'gender', 'level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\log_data contains 30 .json files.\n"
     ]
    }
   ],
   "source": [
    "log_path_list = create_path_list(data_path / 'log_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make sure the data files are in correct chronological order + make sure the data is appended in chronological order!! this way we can keep track whom changes their level accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('data/log_data/2018/11/2018-11-01-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-02-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-03-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-04-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-05-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-06-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-07-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-08-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-09-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-10-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-11-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-12-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-13-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-14-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-15-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-16-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-17-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-18-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-19-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-20-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-21-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-22-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-23-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-24-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-25-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-26-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-27-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-28-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-29-events.json'),\n",
       " WindowsPath('data/log_data/2018/11/2018-11-30-events.json')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(log_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_log_assertions(df: pd.DataFrame, target_columns: list, not_nullable_columns: list = None) -> None:\n",
    "    \"\"\"Assert statements to make sure the retrieved data is valid and clean before insertion into the Postgres table.\"\"\"     \n",
    "    low_df_columns = [x.lower() for x in df.columns]\n",
    "    low_target_columns = [x.lower() for x in target_columns] \n",
    "    \n",
    "    found_cols = [x for x in low_df_columns if x in low_target_columns]    \n",
    "    assert sorted(found_cols) == sorted(low_target_columns), f\"The columns do not match.\"\n",
    "    \n",
    "    if not_nullable_columns:\n",
    "        assert df[not_nullable_columns].isnull().values.any() == False, f\"Missing values in not nullable target columns.\"\n",
    "    else:\n",
    "        assert df[target_columns].isnull().values.any() == False, f\"Missing values in the target columns, if allowed please specify these columns.\"\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_log_insert_list(file_path_list: list, insert_columns: list, primary_keys: list,\n",
    "                           dtype_dict: dict, not_nullable_columns: list = None) -> list:\n",
    "    \"\"\"Takes a raw file_path list as input, performs several validation checks, and returns a list of tuples\n",
    "    ready for insertion in Postgres.\"\"\"\n",
    "    target_df = pd.DataFrame(columns=insert_columns)\n",
    "\n",
    "    for idx, file in enumerate(file_path_list):\n",
    "        temp_df = pd.read_json(file, lines=True)   \n",
    "\n",
    "        try:\n",
    "            df_log_assertions(temp_df, insert_columns, not_nullable_columns)\n",
    "        except AssertionError as error:\n",
    "            print(f\"AssertionError @ file {idx} {file}: {error} NOTE: this file will not be inserted.\")\n",
    "        else:\n",
    "            try:\n",
    "                # we do not want to store non logged in users\n",
    "                temp_df = temp_df[temp_df['auth']=='Logged In']\n",
    "                temp_df[insert_columns] = temp_df[insert_columns].astype(dtype_dict)\n",
    "            except ValueError as error:\n",
    "                print(f\"ValueError @ file {idx} {file}: {error} NOTE: this file will not be inserted\")\n",
    "            else:\n",
    "                target_df = target_df.append(temp_df[insert_columns], ignore_index=True)\n",
    "                \n",
    "    insert_df = target_df.drop_duplicates(subset=primary_keys)\n",
    "    print(f\"There were {target_df.shape[0]-insert_df.shape[0]} duplicate primary keys removed from the insert dataframe\")\n",
    "                \n",
    "    if not_nullable_columns:\n",
    "        insert_df = insert_df.replace({'': None, np.nan: None})  # Postgres does not recognize '' or np.nan as NULL\n",
    "    \n",
    "    # This list comprehension converts the numpy dtypes to standard python dtypes which are necessary for Postgres\n",
    "    return (insert_df, [tuple(row) for row in insert_df.itertuples(index=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 7665 duplicate primary keys removed from the insert dataframe\n"
     ]
    }
   ],
   "source": [
    "log_df, log_tuple_list = create_log_insert_list(file_path_list=log_path_list,\n",
    "                                                insert_columns=users_columns,\n",
    "                                                primary_keys=['userId', 'gender', 'level'],\n",
    "                                                dtype_dict=users_dtype_dict,\n",
    "                                                not_nullable_columns=['userId', 'level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>firstName</th>\n",
       "      <th>lastName</th>\n",
       "      <th>gender</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Walter</td>\n",
       "      <td>Frye</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>Summers</td>\n",
       "      <td>F</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>Cruz</td>\n",
       "      <td>F</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>26</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>Smith</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>101</td>\n",
       "      <td>Jayden</td>\n",
       "      <td>Fox</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>21</td>\n",
       "      <td>Preston</td>\n",
       "      <td>Sanders</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6346</th>\n",
       "      <td>38</td>\n",
       "      <td>Gianna</td>\n",
       "      <td>Jones</td>\n",
       "      <td>F</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6376</th>\n",
       "      <td>5</td>\n",
       "      <td>Elijah</td>\n",
       "      <td>Davis</td>\n",
       "      <td>M</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6688</th>\n",
       "      <td>82</td>\n",
       "      <td>Avery</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>F</td>\n",
       "      <td>paid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7374</th>\n",
       "      <td>22</td>\n",
       "      <td>Sean</td>\n",
       "      <td>Wilson</td>\n",
       "      <td>F</td>\n",
       "      <td>free</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      userId firstName  lastName gender level\n",
       "0         39    Walter      Frye      M  free\n",
       "1          8    Kaylee   Summers      F  free\n",
       "10        10    Sylvie      Cruz      F  free\n",
       "11        26      Ryan     Smith      M  free\n",
       "14       101    Jayden       Fox      M  free\n",
       "...      ...       ...       ...    ...   ...\n",
       "6097      21   Preston   Sanders      M  free\n",
       "6346      38    Gianna     Jones      F  free\n",
       "6376       5    Elijah     Davis      M  free\n",
       "6688      82     Avery  Martinez      F  paid\n",
       "7374      22      Sean    Wilson      F  free\n",
       "\n",
       "[105 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _df_assertions(df: pd.DataFrame, target_columns: list, not_nullable_columns: list = None) -> None:\n",
    "    \"\"\"Assert statements to make sure the retrieved data is valid and clean before insertion into the Postgres table.\"\"\"     \n",
    "    low_df_columns = [x.lower() for x in df.columns]\n",
    "    low_target_columns = [x.lower() for x in target_columns] \n",
    "    \n",
    "    found_cols = [x for x in low_df_columns if x in low_target_columns]    \n",
    "    assert sorted(found_cols) == sorted(low_target_columns), f\"The columns do not match.\"\n",
    "    \n",
    "    if not_nullable_columns:\n",
    "        assert df[not_nullable_columns].isnull().values.any() == False, f\"Missing values in not nullable target columns.\"\n",
    "    else:\n",
    "        assert df[target_columns].isnull().values.any() == False, f\"Missing values in the target columns, if allowed please specify these columns.\"\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _expand_ms(ms_series: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"Expands a Pandas series of milliseconds with several datetime attributes.\"\"\"\n",
    "    df = pd.DataFrame({'start_time': pd.to_datetime(ms_series, unit='ms')})\n",
    "    \n",
    "    df['hour'] = df['start_time'].dt.hour\n",
    "    df['day'] = df['start_time'].dt.day\n",
    "    df['day'] = df['start_time'].dt.isocalendar().week  \n",
    "    df['month'] = df['start_time'].dt.month\n",
    "    df['year'] = df['start_time'].dt.year\n",
    "    df['weekday'] = df['start_time'].dt.weekday\n",
    "\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_log_insert_lists(file_path_list: list, insert_columns: list, primary_keys: list,\n",
    "                            dtype_dict: dict, not_nullable_columns: list = None) -> list:\n",
    "    \"\"\"Takes a raw file_path list as input, performs several validation checks, and returns a list of tuples\n",
    "    ready for insertion in Postgres.\"\"\"\n",
    "    target_df = pd.DataFrame(columns=insert_columns)\n",
    "\n",
    "    for idx, file in enumerate(file_path_list):\n",
    "        temp_df = pd.read_json(file, lines=True)   \n",
    "\n",
    "        try:\n",
    "            _df_log_assertions(temp_df, insert_columns, not_nullable_columns)\n",
    "        except AssertionError as error:\n",
    "            print(f\"AssertionError @ file {idx} {file}: {error} NOTE: this file will not be inserted.\")\n",
    "        else:\n",
    "            try:\n",
    "                # we do not want to store non logged in users\n",
    "                temp_df = temp_df[temp_df['auth']=='Logged In']\n",
    "                temp_df[insert_columns] = temp_df[insert_columns].astype(dtype_dict)\n",
    "            except ValueError as error:\n",
    "                print(f\"ValueError @ file {idx} {file}: {error} NOTE: this file will not be inserted\")\n",
    "            else:\n",
    "                target_df = target_df.append(temp_df[insert_columns], ignore_index=True)\n",
    "                \n",
    "    insert_users_df = target_df.drop_duplicates(subset=primary_keys)\n",
    "    print(f\"There were {target_df.shape[0]-insert_users_df.shape[0]} duplicate primary keys removed from the insert dataframe\")\n",
    "    \n",
    "    insert_time_df = _expand_ms(target_df['ts'])\n",
    "                \n",
    "    if not_nullable_columns:\n",
    "        insert_users_df = insert_users_df.replace({'': None, np.nan: None})  # Postgres does not recognize '' or np.nan as NULL\n",
    "    \n",
    "    # The list comprehension converts the numpy dtypes to standard python dtypes which are necessary for Postgres\n",
    "    return ([tuple(row) for row in insert_users_df.itertuples(index=False)], [tuple(row) for row in insert_time_df.itertuples(index=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dtype_dict = {'userId': int,\n",
    "                  'firstName': str, \n",
    "                  'lastName': str,\n",
    "                  'gender': str,\n",
    "                  'level': str,\n",
    "                  'ts': int} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_columns = ['userId', 'firstName', 'lastName', 'gender', 'level', 'ts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 7665 duplicate primary keys removed from the insert dataframe\n"
     ]
    }
   ],
   "source": [
    "users_table_data, time_table_data = create_log_insert_lists(file_path_list=log_path_list,\n",
    "                                                            insert_columns=log_columns,\n",
    "                                                            primary_keys=['userId', 'gender', 'level'],\n",
    "                                                            dtype_dict=log_dtype_dict,\n",
    "                                                            not_nullable_columns=['userId', 'level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7770"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(time_table_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time table\n",
    "- start_time, hour, day, week, month, year, weekday\n",
    "- ts (timestamp) of records in log data with page=NextSong\n",
    "- Convert back to ms when joining on the other tables..if necessary..\n",
    "\n",
    "#### Extract Data for Time Table\n",
    "- Filter records by `NextSong` action\n",
    "- Convert the `ts` timestamp column to datetime\n",
    "  - Hint: the current timestamp is in milliseconds\n",
    "- Extract the timestamp, hour, day, week of year, month, year, and weekday from the `ts` column and set `time_data` to a list containing these values in order\n",
    "  - Hint: use pandas' [`dt` attribute](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.html) to access easily datetimelike properties.\n",
    "- Specify labels for these columns and set to `column_labels`\n",
    "- Create a dataframe, `time_df,` containing the time data for this file by combining `column_labels` and `time_data` into a dictionary and converting this into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\log_data contains 30 .json files.\n"
     ]
    }
   ],
   "source": [
    "log_path_list = create_path_list(data_path / 'log_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = pd.read_json(log_path_list[0], lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>auth</th>\n",
       "      <th>firstName</th>\n",
       "      <th>gender</th>\n",
       "      <th>itemInSession</th>\n",
       "      <th>lastName</th>\n",
       "      <th>length</th>\n",
       "      <th>level</th>\n",
       "      <th>location</th>\n",
       "      <th>method</th>\n",
       "      <th>page</th>\n",
       "      <th>registration</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>song</th>\n",
       "      <th>status</th>\n",
       "      <th>ts</th>\n",
       "      <th>userAgent</th>\n",
       "      <th>userId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Walter</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Frye</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>San Francisco-Oakland-Hayward, CA</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>1540919166796</td>\n",
       "      <td>38</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1541105830796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Summers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1541106106796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Des'ree</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>Summers</td>\n",
       "      <td>246.30812</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>You Gotta Be</td>\n",
       "      <td>200</td>\n",
       "      <td>1541106106796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Summers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>GET</td>\n",
       "      <td>Upgrade</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1541106132796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mr Oizo</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>Summers</td>\n",
       "      <td>144.03873</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>Flat 55</td>\n",
       "      <td>200</td>\n",
       "      <td>1541106352796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tamba Trio</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>Summers</td>\n",
       "      <td>177.18812</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>Quem Quiser Encontrar O Amor</td>\n",
       "      <td>200</td>\n",
       "      <td>1541106496796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Mars Volta</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>Summers</td>\n",
       "      <td>380.42077</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>Eriatarka</td>\n",
       "      <td>200</td>\n",
       "      <td>1541106673796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Infected Mushroom</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>6</td>\n",
       "      <td>Summers</td>\n",
       "      <td>440.26730</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>Becoming Insane</td>\n",
       "      <td>200</td>\n",
       "      <td>1541107053796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Blue October / Imogen Heap</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>7</td>\n",
       "      <td>Summers</td>\n",
       "      <td>241.39710</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>Congratulations</td>\n",
       "      <td>200</td>\n",
       "      <td>1541107493796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Girl Talk</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Kaylee</td>\n",
       "      <td>F</td>\n",
       "      <td>8</td>\n",
       "      <td>Summers</td>\n",
       "      <td>160.15628</td>\n",
       "      <td>free</td>\n",
       "      <td>Phoenix-Mesa-Scottsdale, AZ</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1540344794796</td>\n",
       "      <td>139</td>\n",
       "      <td>Once again</td>\n",
       "      <td>200</td>\n",
       "      <td>1541107734796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Black Eyed Peas</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Sylvie</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>Cruz</td>\n",
       "      <td>214.93506</td>\n",
       "      <td>free</td>\n",
       "      <td>Washington-Arlington-Alexandria, DC-VA-MD-WV</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1540266185796</td>\n",
       "      <td>9</td>\n",
       "      <td>Pump It</td>\n",
       "      <td>200</td>\n",
       "      <td>1541108520796</td>\n",
       "      <td>\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Smith</td>\n",
       "      <td>NaN</td>\n",
       "      <td>free</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "      <td>1541016707796</td>\n",
       "      <td>169</td>\n",
       "      <td>None</td>\n",
       "      <td>200</td>\n",
       "      <td>1541109015796</td>\n",
       "      <td>\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fall Out Boy</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>Smith</td>\n",
       "      <td>200.72444</td>\n",
       "      <td>free</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1541016707796</td>\n",
       "      <td>169</td>\n",
       "      <td>Nobody Puts Baby In The Corner</td>\n",
       "      <td>200</td>\n",
       "      <td>1541109125796</td>\n",
       "      <td>\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M.I.A.</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>Smith</td>\n",
       "      <td>233.71710</td>\n",
       "      <td>free</td>\n",
       "      <td>San Jose-Sunnyvale-Santa Clara, CA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1541016707796</td>\n",
       "      <td>169</td>\n",
       "      <td>Mango Pickle Down River (With The Wilcannia Mob)</td>\n",
       "      <td>200</td>\n",
       "      <td>1541109325796</td>\n",
       "      <td>\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Survivor</td>\n",
       "      <td>Logged In</td>\n",
       "      <td>Jayden</td>\n",
       "      <td>M</td>\n",
       "      <td>0</td>\n",
       "      <td>Fox</td>\n",
       "      <td>245.36771</td>\n",
       "      <td>free</td>\n",
       "      <td>New Orleans-Metairie, LA</td>\n",
       "      <td>PUT</td>\n",
       "      <td>NextSong</td>\n",
       "      <td>1541033612796</td>\n",
       "      <td>100</td>\n",
       "      <td>Eye Of The Tiger</td>\n",
       "      <td>200</td>\n",
       "      <td>1541110994796</td>\n",
       "      <td>\"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebK...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        artist       auth firstName gender  itemInSession  \\\n",
       "0                         None  Logged In    Walter      M              0   \n",
       "1                         None  Logged In    Kaylee      F              0   \n",
       "2                      Des'ree  Logged In    Kaylee      F              1   \n",
       "3                         None  Logged In    Kaylee      F              2   \n",
       "4                      Mr Oizo  Logged In    Kaylee      F              3   \n",
       "5                   Tamba Trio  Logged In    Kaylee      F              4   \n",
       "6               The Mars Volta  Logged In    Kaylee      F              5   \n",
       "7            Infected Mushroom  Logged In    Kaylee      F              6   \n",
       "8   Blue October / Imogen Heap  Logged In    Kaylee      F              7   \n",
       "9                    Girl Talk  Logged In    Kaylee      F              8   \n",
       "10             Black Eyed Peas  Logged In    Sylvie      F              0   \n",
       "11                        None  Logged In      Ryan      M              0   \n",
       "12                Fall Out Boy  Logged In      Ryan      M              1   \n",
       "13                      M.I.A.  Logged In      Ryan      M              2   \n",
       "14                    Survivor  Logged In    Jayden      M              0   \n",
       "\n",
       "   lastName     length level                                      location  \\\n",
       "0      Frye        NaN  free             San Francisco-Oakland-Hayward, CA   \n",
       "1   Summers        NaN  free                   Phoenix-Mesa-Scottsdale, AZ   \n",
       "2   Summers  246.30812  free                   Phoenix-Mesa-Scottsdale, AZ   \n",
       "3   Summers        NaN  free                   Phoenix-Mesa-Scottsdale, AZ   \n",
       "4   Summers  144.03873  free                   Phoenix-Mesa-Scottsdale, AZ   \n",
       "5   Summers  177.18812  free                   Phoenix-Mesa-Scottsdale, AZ   \n",
       "6   Summers  380.42077  free                   Phoenix-Mesa-Scottsdale, AZ   \n",
       "7   Summers  440.26730  free                   Phoenix-Mesa-Scottsdale, AZ   \n",
       "8   Summers  241.39710  free                   Phoenix-Mesa-Scottsdale, AZ   \n",
       "9   Summers  160.15628  free                   Phoenix-Mesa-Scottsdale, AZ   \n",
       "10     Cruz  214.93506  free  Washington-Arlington-Alexandria, DC-VA-MD-WV   \n",
       "11    Smith        NaN  free            San Jose-Sunnyvale-Santa Clara, CA   \n",
       "12    Smith  200.72444  free            San Jose-Sunnyvale-Santa Clara, CA   \n",
       "13    Smith  233.71710  free            San Jose-Sunnyvale-Santa Clara, CA   \n",
       "14      Fox  245.36771  free                      New Orleans-Metairie, LA   \n",
       "\n",
       "   method      page   registration  sessionId  \\\n",
       "0     GET      Home  1540919166796         38   \n",
       "1     GET      Home  1540344794796        139   \n",
       "2     PUT  NextSong  1540344794796        139   \n",
       "3     GET   Upgrade  1540344794796        139   \n",
       "4     PUT  NextSong  1540344794796        139   \n",
       "5     PUT  NextSong  1540344794796        139   \n",
       "6     PUT  NextSong  1540344794796        139   \n",
       "7     PUT  NextSong  1540344794796        139   \n",
       "8     PUT  NextSong  1540344794796        139   \n",
       "9     PUT  NextSong  1540344794796        139   \n",
       "10    PUT  NextSong  1540266185796          9   \n",
       "11    GET      Home  1541016707796        169   \n",
       "12    PUT  NextSong  1541016707796        169   \n",
       "13    PUT  NextSong  1541016707796        169   \n",
       "14    PUT  NextSong  1541033612796        100   \n",
       "\n",
       "                                                song  status             ts  \\\n",
       "0                                               None     200  1541105830796   \n",
       "1                                               None     200  1541106106796   \n",
       "2                                       You Gotta Be     200  1541106106796   \n",
       "3                                               None     200  1541106132796   \n",
       "4                                            Flat 55     200  1541106352796   \n",
       "5                       Quem Quiser Encontrar O Amor     200  1541106496796   \n",
       "6                                          Eriatarka     200  1541106673796   \n",
       "7                                    Becoming Insane     200  1541107053796   \n",
       "8                                    Congratulations     200  1541107493796   \n",
       "9                                         Once again     200  1541107734796   \n",
       "10                                           Pump It     200  1541108520796   \n",
       "11                                              None     200  1541109015796   \n",
       "12                    Nobody Puts Baby In The Corner     200  1541109125796   \n",
       "13  Mango Pickle Down River (With The Wilcannia Mob)     200  1541109325796   \n",
       "14                                  Eye Of The Tiger     200  1541110994796   \n",
       "\n",
       "                                            userAgent  userId  \n",
       "0   \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...      39  \n",
       "1   \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  \n",
       "2   \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  \n",
       "3   \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  \n",
       "4   \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  \n",
       "5   \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  \n",
       "6   \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  \n",
       "7   \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  \n",
       "8   \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  \n",
       "9   \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebK...       8  \n",
       "10  \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_4...      10  \n",
       "11  \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...      26  \n",
       "12  \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...      26  \n",
       "13  \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/5...      26  \n",
       "14  \"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebK...     101  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1541105830796\n",
       "1    1541106106796\n",
       "2    1541106106796\n",
       "3    1541106132796\n",
       "4    1541106352796\n",
       "Name: ts, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df['ts'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_ms(ms_series: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"Expands a Pandas series with milliseconds with several datetime attributes.\"\"\"\n",
    "    df = pd.DataFrame({'start_time': pd.to_datetime(ms_series, unit='ms')})\n",
    "    \n",
    "    df['hour'] = df['start_time'].dt.hour\n",
    "    df['day'] = df['start_time'].dt.day\n",
    "    df['day'] = df['start_time'].dt.isocalendar().week  \n",
    "    df['month'] = df['start_time'].dt.month\n",
    "    df['year'] = df['start_time'].dt.year\n",
    "    df['weekday'] = df['start_time'].dt.weekday\n",
    "\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-01 20:57:10.796</td>\n",
       "      <td>20</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-01 21:01:46.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-01 21:01:46.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-01 21:02:12.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-01 21:05:52.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-11-01 21:08:16.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-11-01 21:11:13.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-11-01 21:17:33.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-11-01 21:24:53.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-11-01 21:28:54.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-11-01 21:42:00.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-11-01 21:50:15.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-11-01 21:52:05.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-11-01 21:55:25.796</td>\n",
       "      <td>21</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-11-01 22:23:14.796</td>\n",
       "      <td>22</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>2018</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                start_time  hour  day  month  year  weekday\n",
       "0  2018-11-01 20:57:10.796    20   44     11  2018        3\n",
       "1  2018-11-01 21:01:46.796    21   44     11  2018        3\n",
       "2  2018-11-01 21:01:46.796    21   44     11  2018        3\n",
       "3  2018-11-01 21:02:12.796    21   44     11  2018        3\n",
       "4  2018-11-01 21:05:52.796    21   44     11  2018        3\n",
       "5  2018-11-01 21:08:16.796    21   44     11  2018        3\n",
       "6  2018-11-01 21:11:13.796    21   44     11  2018        3\n",
       "7  2018-11-01 21:17:33.796    21   44     11  2018        3\n",
       "8  2018-11-01 21:24:53.796    21   44     11  2018        3\n",
       "9  2018-11-01 21:28:54.796    21   44     11  2018        3\n",
       "10 2018-11-01 21:42:00.796    21   44     11  2018        3\n",
       "11 2018-11-01 21:50:15.796    21   44     11  2018        3\n",
       "12 2018-11-01 21:52:05.796    21   44     11  2018        3\n",
       "13 2018-11-01 21:55:25.796    21   44     11  2018        3\n",
       "14 2018-11-01 22:23:14.796    22   44     11  2018        3"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_ms(log_df['ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   start_time  15 non-null     datetime64[ns]\n",
      " 1   hour        15 non-null     int64         \n",
      " 2   day         15 non-null     UInt32        \n",
      " 3   month       15 non-null     int64         \n",
      " 4   year        15 non-null     int64         \n",
      " 5   weekday     15 non-null     int64         \n",
      "dtypes: UInt32(1), datetime64[ns](1), int64(4)\n",
      "memory usage: 803.0 bytes\n"
     ]
    }
   ],
   "source": [
    "expand_ms(log_df['ts']).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['start_time', 'hour', 'day', 'month', 'year', 'weekday']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(expand_ms(log_df['ts']).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Songplays\n",
    "\n",
    "#### Extract Data and Songplays Table\n",
    "This one is a little more complicated since information from the songs table, artists table, and original log file are all needed for the `songplays` table. Since the log file does not specify an ID for either the song or the artist, you'll need to get the song ID and artist ID by querying the songs and artists tables to find matches based on song title, artist name, and song duration time.\n",
    "- Implement the `song_select` query in `sql_queries.py` to find the song ID and artist ID based on the title, artist name, and duration of a song.\n",
    "- Select the timestamp, user ID, level, song ID, artist ID, session ID, location, and user agent and set to `songplay_data`\n",
    "\n",
    "#### Insert Records into Songplays Table\n",
    "- Implement the `songplay_table_insert` query and run the cell below to insert records for the songplay actions in this log file into the `songplays` table. Remember to run `create_tables.py` before running the cell below to ensure you've created/resetted the `songplays` table in the sparkify database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
